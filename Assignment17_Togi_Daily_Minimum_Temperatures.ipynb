{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment17_Togi_Daily_Minimum_Temperatures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaqI1I1fkT2P"
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/Deep_Learning/daily-min-temperatures.zip'\n",
        "!cp {zip_path} /content/\n",
        "!cd /content/\n",
        "!unzip -q /content/daily-min-temperatures.zip -d /content\n",
        "!rm /content/daily-min-temperatures.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ6eWGguktGw"
      },
      "source": [
        "# From: https://machinelearningmastery.com/exploratory-configuration-multilayer-perceptron-network-time-series-forecasting/\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XypgvXsHkyCJ"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l5g9a5alkCS"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjhN366Olhi3",
        "outputId": "b160c776-0783-4177-e970-be70352829b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1981-01-01    20.7\n",
              "1981-01-02    17.9\n",
              "1981-01-03    18.8\n",
              "1981-01-04    14.6\n",
              "1981-01-05    15.8\n",
              "Name: Temp, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RfmZf2cnRFq"
      },
      "source": [
        "## Plot Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glWm-XhvmTbl",
        "outputId": "79c0e3a8-98c1-43ac-ddcc-4d9b18912046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "dataset.plot(figsize=(15,5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Par1j2lsnYBl"
      },
      "source": [
        "## Processing Time-series Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQrJuUTNnbk9"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ZdM6AVnfbu"
      },
      "source": [
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = pd.concat(columns, axis=1)\n",
        "\treturn df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlUeBC6enjz3",
        "outputId": "cf2bb77d-c87d-4a7f-ce17-4ee48796b34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "raw_values = dataset.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -2.8\n",
              "1       0.9\n",
              "2      -4.2\n",
              "3       1.2\n",
              "4       0.0\n",
              "       ... \n",
              "3644   -0.6\n",
              "3645   -0.4\n",
              "3646   -0.1\n",
              "3647    2.2\n",
              "3648   -2.7\n",
              "Length: 3649, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0miKJWl1noNF",
        "outputId": "2d740819-11e6-4098-b8df-cd98887eaa7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.8</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9</td>\n",
              "      <td>-4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-4.2</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3644</th>\n",
              "      <td>1.7</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>2.2</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0    0\n",
              "0     NaN -2.8\n",
              "1    -2.8  0.9\n",
              "2     0.9 -4.2\n",
              "3    -4.2  1.2\n",
              "4     1.2  0.0\n",
              "...   ...  ...\n",
              "3644  1.7 -0.6\n",
              "3645 -0.6 -0.4\n",
              "3646 -0.4 -0.1\n",
              "3647 -0.1  2.2\n",
              "3648  2.2 -2.7\n",
              "\n",
              "[3649 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzR0h2v1nsvE",
        "outputId": "20bf3512-c61c-4bde-ec59-daab7ead89c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8,  0.9],\n",
              "       [ 0.9, -4.2],\n",
              "       [-4.2,  1.2],\n",
              "       ...,\n",
              "       [-0.4, -0.1],\n",
              "       [-0.1,  2.2],\n",
              "       [ 2.2, -2.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VShAZQyQnz0T"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTpZx7Agn17v"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqF7nz_xn5IF",
        "outputId": "27abf29f-ae8a-4731-cc5a-b1ae4c152cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "train_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11607143,  0.21428571],\n",
              "       [ 0.21428571, -0.24107143],\n",
              "       [-0.24107143,  0.24107143],\n",
              "       ...,\n",
              "       [-0.16071429,  0.375     ],\n",
              "       [ 0.375     ,  0.125     ],\n",
              "       [ 0.125     , -0.16071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdG77n5In82H"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMzfrJZnn-k6",
        "outputId": "056048aa-22c9-4416-ac2d-0e7622bfa810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0656\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0585\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0623 - val_loss: 0.0568\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0613 - val_loss: 0.0564\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0563\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0562\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0561\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0561\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0561\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0561\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0561\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0561\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0561\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0559\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0559\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0559\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0559\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0559\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cnkk6pqoMg8",
        "outputId": "b7e40cc0-945e-4f93-e50b-21da32ec1562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0560\n",
            "Test loss: 0.055963292717933655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUstCcJSoQlg"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq8t6eeSoT48",
        "outputId": "ee155f99-e212-40fc-db85-5eee221bc667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0.060679</td>\n",
              "      <td>0.055941</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.060667</td>\n",
              "      <td>0.055941</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>0.060661</td>\n",
              "      <td>0.055942</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>0.060653</td>\n",
              "      <td>0.055942</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>0.060663</td>\n",
              "      <td>0.055942</td>\n",
              "      <td>507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061079</td>\n",
              "      <td>0.056272</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061350</td>\n",
              "      <td>0.056435</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.062268</td>\n",
              "      <td>0.056826</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066284</td>\n",
              "      <td>0.058458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.083426</td>\n",
              "      <td>0.065642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "90   0.060679  0.055941     90\n",
              "95   0.060667  0.055941     95\n",
              "190  0.060661  0.055942    190\n",
              "411  0.060653  0.055942    411\n",
              "507  0.060663  0.055942    507\n",
              "..        ...       ...    ...\n",
              "4    0.061079  0.056272      4\n",
              "3    0.061350  0.056435      3\n",
              "2    0.062268  0.056826      2\n",
              "1    0.066284  0.058458      1\n",
              "0    0.083426  0.065642      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGxWOoyCoYij",
        "outputId": "40644c9f-34a6-4919-e228-e95bbc764069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xcZZ3n8c+v7n1LJ+mQTkgiCRBkgQhoRBgF42UUXceMChMQERlGVh3v+3IHR8ZxeDE7q8zqLLuMDLOCgCiw4MxkBzQzAm10BlkCBgJBYgy3jiH39L26qk799o9zulPd1V3d1elKd7q/79erXn3Ocy71POdU16+e5znnOebuiIiIjFdsqjMgIiLHFgUOERGpigKHiIhURYFDRESqosAhIiJVSUx1Bo6GBQsW+PLlyye0bU9PDw0NDZOboWlOZZ4dVObZ4UjK/MQTT+xz9+OGp8+KwLF8+XI2bdo0oW3b2tpYs2bN5GZomlOZZweVeXY4kjKb2UsjpaupSkREqqLAISIiVVHgEBGRqsyKPg4RmX3y+Tzt7e1ks9nBtObmZp577rkpzNXRN54yZzIZli5dSjKZHNc+FThEZEZqb2+nqamJ5cuXY2YAdHV10dTUNMU5O7rGKrO7s3//ftrb21mxYsW49qmmKhGZkbLZLC0tLYNBQ0ZmZrS0tAypmY1FgUNEZiwFjfGp9jgpcFRw+7+/yGO7ClOdDRGRaUV9HBV87xcv0WwKHCIyMY2NjXR3d091NiadahwiIlIVBY4KzEDPRxSRI+XufOlLX+KMM85g1apV3HPPPQDs2rWLCy64gLPOOoszzjiDn/3sZwRBwMc+9rHBdb/1rW9Nce7LqamqAkMdayIzwV/832fZ+ttOgiAgHo9Pyj5PO34Of/57p49r3R/+8Ids3ryZp556in379vHGN76RCy64gO9///u8+93v5itf+QpBENDb28vmzZvZuXMnzzzzDACHDh2alPxOJtU4RERq7Oc//zmXXnop8Xic1tZW3vrWt/L444/zxje+kdtuu42vfe1rbNmyhaamJk488UR27NjBZz7zGX784x8zZ86cqc5+GdU4KjADL051LkTkSA3UDKbbDYAXXHABGzdu5IEHHuBjH/sYX/ziF/noRz/KU089xYYNG7j55pu59957ufXWW6c6q0OoxiEiUmPnn38+99xzD0EQsHfvXjZu3Mg555zDSy+9RGtrKx//+Mf5oz/6I5588kn27dtHsVjkQx/6ENdffz1PPvnkVGe/jGocY1DnuIgcqQ984AM8+uijnHnmmZgZ3/jGN1i0aBG33347N9xwA8lkksbGRu644w527tzJlVdeSbEYNnf81V/91RTnvpwCRwW661REjsTAPRxmxg033MANN9wwZPkVV1zBFVdcUbbddKxllFJTlYiIVEWBowIDXG1VIiJDKHBUoJYqEZFyChxjUIVDRGQoBY4KVOMQESmnwFGBhhwRESmnwDEGNVWJiAylwFGBGYocInLUNDY2jrrsxRdf5IwzzjiKuRmdAkcFaqgSESmnO8fHoAqHyAzwo2vg1S3UBQWIT9LX3qJV8J7/VnGVa665hmXLlvHHf/zHAHzta18jkUjwyCOPcPDgQfL5PNdffz1r166t6q2z2Syf/OQn2bRpE4lEgm9+85u87W1v49lnn+XKK68kl8tRLBa5//77aWpq4pJLLqG9vZ0gCPizP/sz1q1bN+FigwJHZbqsSkSOwLp16/j85z8/GDjuvfdeNmzYwGc/+1nmzJnDvn37OPfcc3n/+99f1RBHN910E2bGli1b+NWvfsW73vUutm3bxs0338znPvc5LrvsMnK5HEEQcP/993P88cfzwAMPANDR0XHE5VLgGINqHCIzQFQz6DvKw6qfffbZ7Nmzh9/+9rfs3buXefPmsWjRIr7whS+wceNGYrEYO3fuZPfu3SxatGjc+/35z3/OZz7zGQBOPfVUTjjhBLZt28Z5553HX/7lX9Le3s4HP/hBVq5cyWmnnca1117Ln/zJn/C+972P888//4jLpT6OCgwUOUTkiFx88cXcd9993HPPPaxbt4677rqLvXv38sQTT7B582ZaW1vJZrOT8l4f/vCHWb9+PXV1dbz3ve/l4YcfZuXKlTz55JOsWrWKa6+9luuuu+6I36emgcPMLjSz581su5ldM8LytJndEy1/zMyWR+lJM7vdzLaY2XNm9uXx7nNy81/LvYvIbLBu3Truvvtu7rvvPi6++GI6OjpYuHAhyWSSRx55hJdeeqnqfZ5//vncddddAGzbto2XX36Z1772tezYsYMTTzyRz372s6xdu5ann36aXbt2UV9fz0c+8hG+9KUvTcrIuzVrqjKzOHAT8LtAO/C4ma13960lq10FHHT3k83sEuDrwDrgYiDt7qvMrB7YamY/AF4Zxz4nlavKISJH4PTTT6erq4slS5awePFiLrvsMn7v936PVatWsXr1ak499dSq9/mpT32KT37yk6xatYpEIsF3v/td0uk09957L3feeSfJZJJFixbxp3/6p/z0pz/loosuIhaLkUwm+fa3v33EZaplH8c5wHZ33wFgZncDa4HSL/m1wNei6fuA/2U2ePdEg5klgDogB3SOc5+TRhUOEZkMW7ZsGZxesGABjz766IjrDTy/YyTLly/nmWeeASCTyXDbbbeVrXPNNddwzTVDG2Le+c538oEPfGAi2R5VLQPHEsIawoB24E2jrePuBTPrAFoIg8haYBdQD3zB3Q+Y2Xj2CYCZXQ1cDdDa2kpbW1vVBejs7CNOMKFtj2Xd3d0q8yww08vc3NxMV1fXkLQgCMrSZrrxljmbzY778zBdr6o6BwiA44F5wM/M7CfV7MDdbwFuAVi9erWvWbOm6kz8z+f+nb7uDiay7bGsra1NZZ4FZnqZn3vuubIrqLqO8lVVE7FlyxYuv/zyIWnpdJrHHntsQvsbb5kzmQxnn332uPZZy8CxE1hWMr80ShtpnfaoWaoZ2A98GPixu+eBPWb2b8BqwtrGWPucNGqqEjm2ufsx9wjoVatWsXnz5qP6nl7lE+tqeVXV48BKM1thZingEmD9sHXWAwMP3L0IeNjDErwMvB3AzBqAc4FfjXOfk0pPABQ5NmUyGfbv31/1l+Js4+7s37+fTCYz7m1qVuOI+iw+DWwA4sCt7v6smV0HbHL39cB3gDvNbDtwgDAQQHjl1G1m9izhD//b3P1pgJH2WasyHGM/VESkxNKlS2lvb2fv3r2DadlstqovyJlgPGXOZDIsXbp03PusaR+Huz8IPDgs7asl01nCS2+Hb9c9Uvpo+6wVPY9D5NiVTCZZsWLFkLS2trZxt+PPFLUos+4cH4MquSIiQylwVGLq4xARGU6BowI1VImIlFPgEBGRqihwVKCrqkREyilwjEFdHCIiQylwVKDLcUVEyilwVKCmKhGRcgocY9DluCIiQylwVGCmPg4RkeEUOCpQH4eISDkFDhERqYoCRwXqHBcRKafAMQZ1jouIDKXAMQbFDRGRoRQ4KjjWHjkpInI0KHCIiEhVFDgqMNRUJSIynAJHBWqpEhEpp8AxFlU5RESGUOCoQE1VIiLlFDgq0FVVIiLlFDjGoBqHiMhQChwVqL4hIlJOgUNERKqiwFGBmcaqEhEZToGjIjVWiYgMV9PAYWYXmtnzZrbdzK4ZYXnazO6Jlj9mZsuj9MvMbHPJq2hmZ0XL2qJ9DixbWMsyqMIhIjJUzQKHmcWBm4D3AKcBl5rZacNWuwo46O4nA98Cvg7g7ne5+1nufhZwOfCCu28u2e6ygeXuvqd2ZajVnkVEjl21rHGcA2x39x3ungPuBtYOW2ctcHs0fR/wDiu/eeLSaNujTnFDRKRcoob7XgK8UjLfDrxptHXcvWBmHUALsK9knXWUB5zbzCwA7geudy/vwjazq4GrAVpbW2lra6u6APv2ZQmCYELbHsu6u7tV5llAZZ4dalHmWgaOI2ZmbwJ63f2ZkuTL3H2nmTURBo7LgTuGb+vutwC3AKxevdrXrFlT9fv/4JVN7Ondw0S2PZa1tbWpzLOAyjw71KLMtWyq2gksK5lfGqWNuI6ZJYBmYH/J8kuAH5Ru4O47o79dwPcJm8REROQoqWXgeBxYaWYrzCxFGATWD1tnPXBFNH0R8PBAs5OZxYA/oKR/w8wSZrYgmk4C7wOeoUYM01VVIiLD1KypKuqz+DSwAYgDt7r7s2Z2HbDJ3dcD3wHuNLPtwAHC4DLgAuAVd99RkpYGNkRBIw78BPj7WpVBV1WJiJSraR+Huz8IPDgs7asl01ng4lG2bQPOHZbWA7xh0jNagWocIiJD6c7xCkwP5BARKaPAUYHpTg4RkTIKHGNQhUNEZCgFjkpU4RARKaPAMQbVOEREhlLgqMBAkUNEZBgFjgrKx1sUEZGqAoeZNUTDpc8aqnCIiAxVMXCYWczMPmxmD5jZHuBXwC4z22pmN5jZyUcnm1ND9Q0RkXJj1TgeAU4Cvgwscvdl7r4QeAvwC+DrZvaRGudxyqilSkSk3FhDjrzT3fPDE939AOGQ5vdH40bNWGqqEhEZaqwax/kDE2a2onSBmX0QYKTAMlOowiEiUm6swPHXJdP3D1t27STnZVoqf7agiMjsNlbgsFGmR5qfcXQ5rohIubECh48yPdL8jKOwISJSbqzO8RPNbD3hd+jANNH8itE3mzlmfHQUEanSWIFjbcn0Xw9bNnx+5jH1cYiIDFcxcLj7T0vno0tvzwB2uvueWmZsOtDzOEREyo115/jNZnZ6NN0MPAXcAfzSzC49CvkTEZFpZsz7ONz92Wj6SmCbu68ifO73f6lpzqYBM/VxiIgMN1bgyJVM/y7wjwDu/mrNcjSNqKFKRKTcWIHjkJm9z8zOBt4M/BjAzBJAXa0zJyIi089YV1X9J+BGYBHw+ZKaxjuAB2qZselA9/+JiJQb66qqbcCFI6RvADbUKlPTiS7HFREZqmLgMLMbKy13989ObnamF8PUOS4iMsxYTVWfAJ4B7gV+yyzrL1ZTlYhIubECx2LgYmAdUADuAe5z90O1zpiIiExPFa+qcvf97n6zu7+N8D6OucBWM7t8PDs3swvN7Hkz225m14ywPG1m90TLHzOz5VH6ZWa2ueRVNLOzomVvMLMt0TY3Wg2HsNV9HCIi5ca6HBcAM3s98DngI8CPgCfGsU0cuAl4D3AacKmZnTZstauAg+5+MvAt4OsA7n6Xu5/l7mcBlwMvuPvmaJtvAx8HVkavss77yaO2KhGR4cYacuQ6M3sC+CLwU2C1u1/l7lvHse9zgO3uvsPdc8DdDB00kWj+9mj6PuAdI9QgLo22xcwWA3Pc/Rfu7oTDn/z+OPIyYbqqSkRkqLH6OK4FXgDOjF7/NfpeN8Dd/XUVtl0CvFIy3w68abR13L1gZh1AC7CvZJ11HA44S6L9lO5zyUhvbmZXA1cDtLa20tbWViGrI9u1qx/34oS2PZZ1d3erzLOAyjw71KLMYwWOKX3mhpm9Ceh192eq3dbdbwFuAVi9erWvWbOm6vf/l4NbeHL3y0xk22NZW1ubyjwLqMyzQy3KPFbgeDlqEhqVmdko6+wElpXML43SRlqnPRrGpBnYX7L8EuAHw9ZfOsY+J42hznERkeHG6hx/xMw+Y2avKU00s5SZvd3MbgeuGGXbx4GVZrbCzFKEQWD9sHXWl2x/EfDwQBAysxjwB0T9GwDuvgvoNLNzo76QjwL/NGYpJ0j3cYiIlBurxnEh8IfAD8xsBXAIyABx4F+Av3H3X460YdRn8WnCoUniwK3u/qyZXQdscvf1wHeAO81sO3CAMLgMuAB4xd13DNv1p4DvEg6y+KPoVTuqcoiIDDHWWFVZ4G+Bv42e/rcA6BvvDYDu/iDw4LC0rw7b/8WjbNsGnDtC+ibCpxDWnIYcEREpN1aNY5C754FdNczLtKOmKhGRcuO6AXA2U41DRGQoBY4KVOEQESk33iFHGqKrnDCzU8zs/VGfh4iIzDLjrXFsBDJmtoTwaqrLCa9smtHMTEOOiIgMM97AYe7eC3wQ+Ft3vxg4vXbZEhGR6WrcgcPMzgMu4/CzxuO1ydL0ogqHiMhQ4w0cnwe+DPxDdBPficAjtcvW9KDLcUVEyo3rPg53/ynhsOoDQ4Hsm+nPG4fwBkARERlqvFdVfd/M5phZA+EzyLea2Zdqm7XpQZ3jIiJDjbep6jR37yR8aNKPCIdbH9fjY49laqoSESk33sCRjO7b+H1gfTT8yIz/La64ISJSbryB4++AF4EGYKOZnQB01ipT08mMj44iIlUab+f4jcCNJUkvmdnbapOl6UNNVSIi5cbbOd5sZt80s03R678T1j5mPNU4RESGGm9T1a1AF+ET+f6AsJnqtlplarowM0UOEZFhxvs8jpPc/UMl839hZptrkaHpRC1VIiLlxlvj6DOztwzMmNmbgb7aZGl6UYVDRGSo8dY4PgHcYWbN0fxB4IraZGkaUUuViEiZ8V5V9RRwppnNieY7zezzwNO1zNxU05AjIiLlqnoCoLt3RneQA3yxBvmZflTlEBEZ4kgeHTvjf47HY4obIiLDHUngmPHfqTEzijO+lCIi1anYx2FmXYwcIAyoq0mOppGYGQ64e3hPh4iIVA4c7t50tDIyHf3OK7ewN14kKL6HRFyBQ0QExn857qy0ct9DvDm2QM1VIiIljqSPY8ZzjBhOUU9zEhEZVNPAYWYXmtnzZrbdzK4ZYXnazO6Jlj9mZstLlr3OzB41s2fNbIuZZaL0tmifm6PXwhoWAAMCVTlERAbVrKnKzOLATcDvAu3A42a23t23lqx2FXDQ3U82s0uArwPrzCwBfA+43N2fMrMWIF+y3WXuvqlWeS8pBDGKqnGIiJSoZY3jHGC7u+9w9xxwN7B22Dprgduj6fuAd1h4+dK7gKejO9Zx9/3uHtQwr6OIYUCxePTfWURkuqpl5/gS4JWS+XbgTaOt4+4FM+sAWoBTADezDcBxwN3u/o2S7W4zswC4H7jevbxKYGZXA1cDtLa20tbWVnUBTsnlMIps/PnPaUrNnququru7J3S8jmUq8+ygMk+O6XpVVQJ4C/BGoBd4yMyecPeHCJupdppZE2HguBy4Y/gO3P0W4BaA1atX+5o1a6rOxP4n67A+OPe83+G4pvSEC3OsaWtrYyLH61imMs8OKvPkqGVT1U5gWcn80ihtxHWifo1mYD9h7WSju+9z917gQeD1AO6+M/rbBXyfsEmsRsI+jhEqNCIis1YtA8fjwEozW2FmKeASYP2wddZzeHj2i4CHo2anDcAqM6uPAspbga1mljCzBQBmlgTeBzxTqwK4hX0cgQKHiMigmjVVRX0WnyYMAnHgVnd/1syuAza5+3rgO8CdZrYdOEAYXHD3g2b2TcLg48CD7v6AmTUAG6KgEQd+Avx9rcpg0VVVuhxXROSwmvZxuPuDhM1MpWlfLZnOAhePsu33CC/JLU3rAd4w+TkdhcWAAFU4REQO053jY1CNQ0RkKAWOSmLq4xARGU6Bo6JwrCpdVSUicpgCRyUWI2ZFAt05LiIySIGjEgsPj/o4REQOU+CoRIMcioiUUeCoJLoBUIFDROQwBY4KDN0AKCIynAJHJTHVOEREhlPgqMgwinrmuIhICQWOCmxgkENFDhGRQQoclQxcVaXAISIySIGjksE+jqnOiIjI9KHAUUE4rLqT10PHRUQGKXBUEI/FMZy+XDDVWRERmTYUOCqIx2MYTq8Ch4jIIAWOCgZqHL25wlRnRURk2lDgqCARjxHD6elXjUNEZIACRwWxuGocIiLDKXBUYBhxU41DRKSUAkclFiNuzu7O7FTnRERk2lDgqMSMpDm/3tM11TkREZk2FDgqsRjJGGzb3c1vD/VNdW5ERKYFBY6KjEw8HG/khg3Ps6cri7uTD4rkgyJ7u/rxYUOuF4JiWdpE9OWCsv24Oz39o3fUZ/MBHb153Ee+abFY9CPKWz4oks0HFIY9hD2I9lv6KrWnM0tnNj/h9wXozObHzHuxGJ4boKz8fblgcFm1qh2rbKRjUM22/YWgbGDNgXPX0TvyceyKjm9vrkAhKJIrFMu2Lc1bd8nnyN1HLGM2H9DdXxhSltL9ZPPln7GBtNHyOVKZSg3MVzpXpcemEH0md3WM/MOuEIw91tx4BzGdjP/ro7HPoyEx1RmY1ixGwuATbz2Jm3/6G/7hlztpSMUJ3MkHTlB05tYniZkxty5JKhFjx94eEnEjETMWN9cBsL8nR2+uQFMmQfj/4CyZV8/eziwLmtIc6s0TM+jKhv/MmWScnVEN55TWRvJB+IXY2ZenM1vguKY0TekE+WKROZkkiXiMfKHI1l2dxOzw2FrNdUka0wniMWNOXYLf7OkhlYgxtz5JJhGnvxAQjxld2QJFdzLJOAd7csxJFrFHH+Jgb55MMkbMwnVyJf/MJy5oiMoZY1dHH/2FIr25gPkNqTDA5QJWtDSQC4q8sK8HgIVNaQrFMPjVpeIc6s3TlE6wcE4aM2N+fYrObJ7eXEA6EeNQX57muiR9uYCdh/pYNr+OVDxGoejkCkUyyTiHenOYGY3pBL25AkHRmdeQYsfeHlYsaKAuGWdXRx8Hoy+yM5c2A9CXD8gHTn8+wIF40E/w6EPMq08RFJ2DvTmS8Rj9hYBDvXlOOq6RTDLG/p4wPWaQD5xiFMxbGtPMyYTH+oV9PfQXwi+s4+fWkU7GCIoMfsEZxrL5dXT05UnEwvNRdDjQ08/uzn4A6pJxjmtK05sLj1Vfrgg4+7pz/IfFc0glYgTFIh19edxh56E+jm+uY3dnlkL0AVjcnCFmxs5DfSRiRmMmwaGSL/SWjJH4958MvucJLfXUJeOkEjF+vbubvpLA0JhO0N1fIJWIsbApTfvBPuIx47WtTXT05UknYzRlkjyzswMDCkUnGTcWNmUoeng8s/kiCxpTuENjJsGuQ1lyQZHXLW0mVyjyyoFeeqLP0IGeHOlEjGXz6+nLBezuzDK3PoUZ4fslYszJJAf/T2IGpx/fTE9/gYO9OeKxGKm4caA3R2M6QVMmSVe2wPxknhu3/hv9hfABbalEjF+92sWiORliBj25gEVzMvTlA+qS4f/Iro4syXiMQlBkbn2KeMxIxWMkE0Y2X2RPZ5bXtNQD4f/w3PoUhaA4+DnOBUU6+wq0NKTY1dFHQzpB0Z2WhjTP7+7ihJZ63CERM+IxG/zsHdeUZl93Py0NaQrFIq8c6GN+Q4q+XECh6MypS+AOZpCNfih59NmZU5ek/WAfuULAX705dYRfhOUUOCoxA4pc855T+Y+rFvPYC/tpP9jHjn09FIIiL+3v5azXzB38Eu4vFGlpTNHalCFwp/1gH/WpOCctbGBhU4beXIG+fJG4we7OflKJGHXJOHXNcRbOyWBArlAkHjNWLGggHxRprkuSTsZJxAyzgZpI+M9jxuCHvy8XcP7KBfT0F2hIJ1g6r44DPTkSsRj5oEhfPuA/vm4OmWSMrmyBnv6A/kJAJhknGTf6cgF9+YATWurJdh2ideFc3Af+EZK4w8ZtezllURN1yThz65MExcMBFMIvg1c7spx4XAMLGtN0ZQv05QvUp+LMq0+RScboLxRJxmMERaczm+eUhU3s78kNfiEk4sZrFzURN6M+HaejN0/RnVNaG0kn4vTkCqQTcfryBZrrkvTmAnYdyrKoOcNL+3vo7g9orktiBsvm15OKGwua0mzctpdEzKhLxckk4xyfjOMOTZkERYctL/yWrMVY0JSmGP1TForOipYG6lJxtu3uoi6VYHFzHS8f6GVeQ5K5dSn6C0XaD/ZSl4rTkE5QCJxl8+tpaUiFX1TR34GyL5qTwXHqUwleuyhBfz6sCcXMWNCYonVOhhf29jC3Icmpi5rIForUJWO82pElnYjTlOlnTiZBOhnH3UnEYiRixsKmNMfPreP4uXXs6siypzNLXSoOQDoRoymToKu/wLJ59Zy1bC4HenL8un038+Y20NKQ5oSWeoruZPNFYgbNy+fxwr4eMsk4C5vS0fnMU59K0F8IazQdfXnmNSRZOCdNdzYMKie01PMfFs9hS3sHr5lfj+Ok4mHDRiYZZ04mST4oDv7Q6O0vkIzHqE/FWTZ/Af+6dTcrFjRQn4pz6qKmcJ1cQCoRY3FzhnxQZH9PjtctaR4MbHWpOF3ZPA3pOIubM/TkCsytS5FKxDjUm6MnF9CbK7Bkbh179h+gIZ1gfkOMvnxAd39AMmYc15SmPvps9PQXWDqvjoO9OfryAadFgXpXR5ZTWhvJFcJaoZmRihuLmzMExfCH12vmx9jfnaOuPhn98CjSnw84+bjGwVrUgqYUuUJ4zk9c0EBLY4qWxjT9+SLd/XmaMgkMw3GSsfDcxWPG6Yub6e4v0F8ISMZj9OQCOnpz1KcSzG9M0RH90OvLBxzoyXPm0mYWNWeoT+yb9K9GBY5KzAhjOKxa2syq6NfqTNfW1saaNW+Y6mwcVW1tB1mzZs1UZ+OoCs/zeVOdjaMqLPObpjobR1VbW9uk77OmfRxmdqGZPW9m283smhGWp83snmj5Y2a2vGTZ68zsUTN71sy2mFkmSn9DNL/dzG40M6thCbBjtA1SRKRWahY4zCwO3AS8BzgNuNTMThu22lXAQXc/GfgW8PVo2wTwPeAT7n46sAYYaJz9NvBxYGX0urBWZcBiDNQ4REQkVMsaxznAdnff4e454G5g7bB11gK3R9P3Ae+IahDvAp5296cA3H2/uwdmthiY4+6/8PByhDuA369ZCUw1DhGR4WrZx7EEeKVkvh0Y3rg4uI67F8ysA2gBTgHczDYAxwF3u/s3ovXbh+1zyUhvbmZXA1cDtLa2Tqidb+WuV1ngxZq0EU5n3d3dKvMsoDLPDrUo83TtHE8AbwHeCPQCD5nZE0DHeHfg7rcAtwCsXr3aJ9Tx2b2e3F5maafpmqnOxlGlMs8OKvPkqGVT1U5gWcn80ihtxHWifo1mYD9hTWKju+9z917gQeD10fpLx9jn5LGYmqpERIapZeB4HFhpZivMLAVcAqwfts564Ipo+iLg4ajvYgOwyszqo4DyVmCru+8COs3s3Kgv5KPAP9WsBCWX44qISKhmTZvHfsAAAA1nSURBVFVRn8WnCYNAHLjV3Z81s+uATe6+HvgOcKeZbQcOEAYX3P2gmX2TMPg48KC7PxDt+lPAd4E64EfRqzZ0VZWISJma9nG4+4OEzUylaV8tmc4CF4+y7fcIL8kdnr4JOGNyczoaXVUlIjKcBjmsRDUOEZEyChyV6D4OEZEyChyVqHNcRKSMAkdFChwiIsMpcFRiMcwn9vAfEZGZSoGjknhSgUNEZBgFjkriKYwiBKM/rlVEZLZR4KgkHj1yMeif2nyIiEwjChyVDAaO3NTmQ0RkGlHgqCQRBY6CAoeIyAAFjkri6fCvmqpERAYpcFQy2FSVr7yeiMgsosBRyWBTlWocIiIDFDgqUVOViEgZBY5K1FQlIlJGgaMSNVWJiJRR4KgkkQn/5vumNh8iItOIAkcljQvDv927pzYfIiLTiAJHJU2Lw7+dv53afIiITCMKHJUk0vSnWmD/r6c6JyIi04YCxxgOzT0dtv8Eul6d6qyIiEwLianOwHT3yrLfp/XpTfA3q2D5W+Ckd0DraWEzVrIOLA71LZBIQyw+1dmtrFgMH4drNtU5mb3cw4stUvXVb1cMwAMoZCHVGA6+GU+H53PfNqibB5m5EE+G6xbzhy8lT6TDy8uHn/u+g+G68VR4MYgHUCyE2xUDyMwBi4VXFnoAXgzfx6MnYw7sL9sJ6aZwvnMXZA9By0roOxC+R9PiMM/FPMQSh/eZ7w236+8K9wuQ64GOdmg56fAAo/EU7P9NeNzq5kOyHg6+APNWMPiUzoE89e4P8z1wbNzDY5btwIr58P+gvyN8/8bWsJyxOBx8McxnLB5uE0tALPptPfC/09818rEcOK8eQLIh/Gvx8HhlD0XHNx2+3MN0L4bvMXAe6ueH04VcuAwPz0kxgEJfeFzqWw6fH7NwWbYjXLexNVy/0A/JzOHjUQMKHGPobjoJPv4I/PJO+PW/wr98ZfSV03NKPkwlH6oh/6w2etqQ9EnevhhAz57ww1w3N/wAB4XwH3fwYVXhNm8OCvCL5Mj7MxshD+NdFs2XLWP0ZTj0Hgj/wQa+eIpB+GVTLERfkIWhr2Qd5LPQeFz4BeVF6DsUpo/i3P4sPJkZdTnxFPR3hvvKNEdZKzluuZ7wSy2WCP+R03MO5989/IuF++g7CM3LwnkPDgeEwb/F8vSyRxhP5LHGFgaVIA84awDaqtwFRF+IQTQdKzkO483XKOuU7neyDMvfWwE2jiMvpdsPnKcRl8ejdTz87A1dWL7vsuNVsp7Fw7+ly0dcv4JYIsrH4X3G33zX+LcfJwWO8Vh4Krz7L8NXx87wl0nXrvDXUJALv9hyPZDrDtcfEulLpgfTR0orST/i7SlPg/CXVDwd/noJChBPQKIu/DIp2ffu9ldYumTpCPnx8jyMd9ngn9GW+ejLCtnwV2aQC8vQ3wWxZPSLMBGmDUxbDHJdYbn6Dhwue74v/EU7Sm3r4K5XWbx40YjLcMLRA4pBGDRyPVHNLRbVBArhew/8ivRiuGwgkA5MexH6u6HjZTju1Ci/8fBXrcXDcgz+jQ2bL0mPJ8Nf+Kn6MAgE+fDz2HLS4V+r8ZLjE/SHwaiYD49Dsg4sxosvvsTy4xfAnOPDHxBQkqd4eNwHytd7IPzB4cXoF3p0rIuFsGyF/rAW4AGDgTSRDo/Xnq1hoK9vCfcJ4S/jWOJwULQ45HvCz2c8FZanafHhY1vMh58BD8JjmO8N15l/YvTFPcDCwJxIhZ+BYj5MS9ZBRzsv7OtlxWuWhTUS7HBtoFgI85ysj2oTHP5R4sUwzYvhZy8zN8xzMTh8vvHwx0IsHh7jgSASS4Z5GahdxZKHz6fFwvwNHJNYIsyTF8N1knXRccxEtcFiuI+BaYuF576/M6ytuIffQbmeMC/xJBT6CeIVfhBNkAJHtZqXhK8ZbHtbG0vXrJnqbBxVz7e1sXiWlfnFtjaWz7Iyv9TWxopZVmba2iZ9l+ocFxGRqihwiIhIVWoaOMzsQjN73sy2m9k1IyxPm9k90fLHzGx5lL7czPrMbHP0urlkm7ZonwPLFtayDCIiMlTN+jjMLA7cBPwu0A48bmbr3X1ryWpXAQfd/WQzuwT4OrAuWvYbdz9rlN1f5u6bapV3EREZXS1rHOcA2919h7vngLuBtcPWWQvcHk3fB7zDTDcZiIhMZ7W8qmoJ8ErJfDvwptHWcfeCmXUALdGyFWb2S6ATuNbdf1ay3W1mFgD3A9e7l9/pYmZXA1cDtLa20jbBKwu6u7snvO2xSmWeHVTm2aEWZZ6ul+PuAl7j7vvN7A3AP5rZ6e7eSdhMtdPMmggDx+XAHcN34O63ALcArF692tdM8BK8trY2JrrtsUplnh1U5tmhFmWuZVPVTmBZyfzSKG3EdcwsATQD+9293933A7j7E8BvgFOi+Z3R3y7g+4RNYiIicpTUssbxOLDSzFYQBohLgA8PW2c9cAXwKHAR8LC7u5kdBxxw98DMTgRWAjui4DLX3feZWRJ4H/CTsTLyxBNP7DOzlyZYjgXAvglue6xSmWcHlXl2OJIynzBSYs0CR9Rn8WlgAxAHbnX3Z83sOmCTu68HvgPcaWbbgQOEwQXgAuA6M8sDReAT7n7AzBqADVHQiBMGjb8fR16Om2g5zGyTu6+e6PbHIpV5dlCZZ4dalLmmfRzu/iDw4LC0r5ZMZ4GLR9jufsL+i+HpPcAbJj+nIiIyXrpzXEREqqLAMbZbpjoDU0Blnh1U5tlh0stsI9wCISIiMirVOEREpCoKHCIiUhUFjlGMNbLvscrMlpnZI2a21cyeNbPPRenzzexfzezX0d95UbqZ2Y3RcXjazF4/tSWYODOLm9kvzeyfo/kV0ajM26NRmlNR+oijNh9rzGyumd1nZr8ys+fM7LyZfp7N7AvR5/oZM/uBmWVm2nk2s1vNbI+ZPVOSVvV5NbMrovV/bWZXVJMHBY4RlIzs+x7gNOBSMzttanM1aQrAf3b304BzgT+OynYN8JC7rwQeiuYhPAYro9fVwLePfpYnzeeA50rmvw58y91PBg4SjtYMJaM2A9+K1jsW/Q/gx+5+KnAmYdln7Hk2syXAZ4HV7n4G4b1eA6Nuz6Tz/F3gwmFpVZ1XM5sP/Dnh+IHnAH8+EGzGxd31GvYCzgM2lMx/GfjyVOerRmX9J8Kh758HFkdpi4Hno+m/Ay4tWX9wvWPpRTjkzUPA24F/Jnyq9D4gMfycE960el40nYjWs6kuQ5XlbQZeGJ7vmXyeOTxo6vzovP0z8O6ZeJ6B5cAzEz2vwKXA35WkD1lvrJdqHCMbaWTfGfeg8ahqfjbwGNDq7ruiRa8CrdH0TDkWfwP8F8KRCCAchfmQuxei+dJyDRm1GSgdtflYsQLYSziS9C/N7H9HIy/M2PPs4Th2fw28TDhQagfwBDP7PA+o9rwe0flW4JilzKyR8O78z3s46vAgD3+CzJjrtM3sfcAeDwfMnC0SwOuBb7v72UAPh5svgBl5nucRPuNnBXA80EB5k86MdzTOqwLHyMYzsu8xKxrr637gLnf/YZS828wWR8sXA3ui9JlwLN4MvN/MXiR8oNjbCdv/50YDZ8LQco04avPRzPAkaAfa3f2xaP4+wkAyk8/zO4EX3H2vu+eBHxKe+5l8ngdUe16P6HwrcIxscGTf6AqMSwhH8j3mmZkRDi75nLt/s2TRwEjFRH//qST9o9HVGecCHSVV4mOCu3/Z3Ze6+3LCc/mwu18GPEI4KjOUl3ngWAyO2nwUs3zE3P1V4BUze22U9A5gKzP4PBM2UZ1rZvXR53ygzDP2PJeo9rxuAN5lZvOimtq7orTxmepOnun6At4LbCN8FshXpjo/k1iutxBWY58GNkev9xK27T4E/Jpw1OH50fpGeIXZb4AthFesTHk5jqD8a4B/jqZPBP4fsB34P0A6Ss9E89uj5SdOdb4nWNazgE3Ruf5HYN5MP8/AXwC/Ap4B7gTSM+08Az8g7MPJE9Ysr5rIeQX+MCr7duDKavKgIUdERKQqaqoSEZGqKHCIiEhVFDhERKQqChwiIlIVBQ4REamKAofIJDCzwMw2l7wmbURlM1teOhKqyFRLjL2KiIxDn7ufNdWZEDkaVOMQqSEze9HMvmFmW8zs/5nZyVH6cjN7OHpGwkNm9poovdXM/sHMnopevxPtKm5mfx89a+JfzKxuygols54Ch8jkqBvWVLWuZFmHu68C/hfhKL0A/xO43d1fB9wF3Bil3wj81N3PJBxb6tkofSVwk7ufDhwCPlTj8oiMSneOi0wCM+t298YR0l8E3u7uO6LBJV919xYz20f4/IR8lL7L3ReY2V5gqbv3l+xjOfCvHj6kBzP7EyDp7tfXvmQi5VTjEKk9H2W6Gv0l0wHqn5QppMAhUnvrSv4+Gk3/O+FIvQCXAT+Lph8CPgmDz0hvPlqZFBkv/WoRmRx1Zra5ZP7H7j5wSe48M3uasNZwaZT2GcKn832J8El9V0bpnwNuMbOrCGsWnyQcCVVk2lAfh0gNRX0cq91931TnRWSyqKlKRESqohqHiIhURTUOERGpigKHiIhURYFDRESqosAhIiJVUeAQEZGq/H/l513JOnIHMwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEU6SVD_oeYL"
      },
      "source": [
        "# Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8-DyM5WogEP",
        "outputId": "80ff259b-05d3-4d93-930e-539cb6f1b75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0604\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.0567\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0560\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0559\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0560\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYQPTVjRpFGu",
        "outputId": "b8bfd71b-1fa8-4bef-ee5d-f25caf52d9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "deeper_history_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_history_dataframe['epoch'] = deeper_model_history.epoch\n",
        "deeper_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0.060668</td>\n",
              "      <td>0.055944</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.060661</td>\n",
              "      <td>0.055944</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>0.060662</td>\n",
              "      <td>0.055945</td>\n",
              "      <td>625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>0.060663</td>\n",
              "      <td>0.055946</td>\n",
              "      <td>624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0.060689</td>\n",
              "      <td>0.055946</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>0.060679</td>\n",
              "      <td>0.056009</td>\n",
              "      <td>539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>0.060733</td>\n",
              "      <td>0.056023</td>\n",
              "      <td>562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.060942</td>\n",
              "      <td>0.056027</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.062711</td>\n",
              "      <td>0.056709</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072080</td>\n",
              "      <td>0.060392</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "300  0.060668  0.055944    300\n",
              "259  0.060661  0.055944    259\n",
              "625  0.060662  0.055945    625\n",
              "624  0.060663  0.055946    624\n",
              "146  0.060689  0.055946    146\n",
              "..        ...       ...    ...\n",
              "539  0.060679  0.056009    539\n",
              "562  0.060733  0.056023    562\n",
              "2    0.060942  0.056027      2\n",
              "1    0.062711  0.056709      1\n",
              "0    0.072080  0.060392      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0LSmb22pPdv",
        "outputId": "f9dc6492-1f0d-4313-8006-a1c595d18630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(deeper_model_history) # epoch vs loss graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDg7TMI8eZKT"
      },
      "source": [
        "# Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIUterW4pUX0",
        "outputId": "81e7dccf-d9c5-4787-e409-9644aab89b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0543\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0540\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0546\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0538\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0537\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0537\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0537\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0537\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0545\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0547\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0544\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0538\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0546\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TO31Pn0qTgq",
        "outputId": "126d6443-5312-4ac7-d888-f1bfa11dd429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "wider_history_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_history_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.058146</td>\n",
              "      <td>0.053674</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.057997</td>\n",
              "      <td>0.053726</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.058241</td>\n",
              "      <td>0.053727</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.058159</td>\n",
              "      <td>0.053738</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.057888</td>\n",
              "      <td>0.053742</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>0.057537</td>\n",
              "      <td>0.054562</td>\n",
              "      <td>700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>0.057405</td>\n",
              "      <td>0.054570</td>\n",
              "      <td>822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.058674</td>\n",
              "      <td>0.054593</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>0.057439</td>\n",
              "      <td>0.054627</td>\n",
              "      <td>867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0.057932</td>\n",
              "      <td>0.054731</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "10   0.058146  0.053674     10\n",
              "13   0.057997  0.053726     13\n",
              "5    0.058241  0.053727      5\n",
              "9    0.058159  0.053738      9\n",
              "39   0.057888  0.053742     39\n",
              "..        ...       ...    ...\n",
              "700  0.057537  0.054562    700\n",
              "822  0.057405  0.054570    822\n",
              "2    0.058674  0.054593      2\n",
              "867  0.057439  0.054627    867\n",
              "62   0.057932  0.054731     62\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb1b8LlLqaeQ",
        "outputId": "afec7902-8206-43fe-d215-a0187d232611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(wider_model_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll6KeHX_qms7"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqI5TQbnqsMj",
        "outputId": "abad3415-97d8-4a80-80ed-f6723c5112eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0655 - val_loss: 0.0553\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0541\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0541\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0543\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0543\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0544\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0546\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0545\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0538\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0547\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0544\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0544\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0545\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0546\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0545\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik-f9WdPrHMh",
        "outputId": "d2761030-5976-4710-9e7e-b900519ca874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>0.057868</td>\n",
              "      <td>0.053779</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>0.057941</td>\n",
              "      <td>0.053787</td>\n",
              "      <td>284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.057888</td>\n",
              "      <td>0.053788</td>\n",
              "      <td>324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0.057865</td>\n",
              "      <td>0.053793</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>0.057971</td>\n",
              "      <td>0.053794</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>0.057699</td>\n",
              "      <td>0.054539</td>\n",
              "      <td>612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.057994</td>\n",
              "      <td>0.054553</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>0.057675</td>\n",
              "      <td>0.054564</td>\n",
              "      <td>703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>0.057846</td>\n",
              "      <td>0.054737</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.065547</td>\n",
              "      <td>0.055309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "325  0.057868  0.053779    325\n",
              "284  0.057941  0.053787    284\n",
              "324  0.057888  0.053788    324\n",
              "345  0.057865  0.053793    345\n",
              "275  0.057971  0.053794    275\n",
              "..        ...       ...    ...\n",
              "612  0.057699  0.054539    612\n",
              "196  0.057994  0.054553    196\n",
              "703  0.057675  0.054564    703\n",
              "355  0.057846  0.054737    355\n",
              "0    0.065547  0.055309      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Jtvo_crKse",
        "outputId": "e0c5b079-0988-4de2-de53-b3388ab9f93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31xF1s4ejByr"
      },
      "source": [
        "# Kesimpulan\n",
        "Arsitektur terbaik untuk dataset daily-min-temperatures adalah wider model, dengan nilai val_loss 0.053674 pada epoch ke-10."
      ]
    }
  ]
}